#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ð¡ÐºÑ€Ð¸Ð¿Ñ‚ Ð´Ð»Ñ ÑÐºÐ°Ñ‡Ð¸Ð²Ð°Ð½Ð¸Ñ Ð²ÑÐµÑ… Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¾Ð² Ñ ÑÐ°Ð¹Ñ‚Ð°
"""

import sys
import os
import urllib.request
import json
from pathlib import Path

if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

try:
    import requests
    from bs4 import BeautifulSoup
    HAS_LIBS = True
except ImportError:
    os.system(f"{sys.executable} -m pip install requests beautifulsoup4 --quiet")
    try:
        import requests
        from bs4 import BeautifulSoup
        HAS_LIBS = True
    except:
        HAS_LIBS = False

# ÐŸÑ€ÑÐ¼Ñ‹Ðµ ÑÑÑ‹Ð»ÐºÐ¸ Ð½Ð° ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ñ‹ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¾Ð² Ð¸Ð· Ð²ÐµÐ±-Ð¿Ð¾Ð¸ÑÐºÐ°
PRODUCT_URLS = {
    1: "https://www.qxw18.com/cp/NTcnLlNgJj.html",  # ç»é¢…ç£åˆºæ¿€ä»ª
    10: "https://www.qxw18.com/cp/XMSZmAcpXB.html",  # ä¸­é¢‘ç”µç–—ä»ª
}

# Ð‘Ð°Ð·Ð¾Ð²Ñ‹Ð¹ URL Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ°
BASE_URL = "https://c71541.qxw18.com/"

def download_image(url, filepath):
    """Ð¡ÐºÐ°Ñ‡Ð¸Ð²Ð°ÐµÑ‚ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        req = urllib.request.Request(url, headers=headers)
        with urllib.request.urlopen(req, timeout=15) as response:
            with open(filepath, 'wb') as f:
                f.write(response.read())
        return True
    except Exception as e:
        return False

def extract_images_from_page(url):
    """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ð²ÑÐµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ ÑÐ¾ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ñ‹"""
    if not HAS_LIBS:
        return []
    
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        response = requests.get(url, headers=headers, timeout=15)
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, 'html.parser')
        
        images = []
        for img in soup.find_all('img'):
            src = img.get('src') or img.get('data-src') or img.get('data-original')
            if src:
                if src.startswith('//'):
                    src = 'https:' + src
                elif src.startswith('/'):
                    base = '/'.join(url.split('/')[:3])
                    src = base + src
                elif not src.startswith('http'):
                    continue
                
                # ÐŸÑ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¼Ð°Ð»ÐµÐ½ÑŒÐºÐ¸Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð¸ Ð¸ÐºÐ¾Ð½ÐºÐ¸
                if any(x in src.lower() for x in ['logo', 'icon', 'avatar', 'thumb', 'small', 'btn']):
                    continue
                
                images.append(src)
        
        return list(set(images))
    except:
        return []

def main():
    print("=" * 80)
    print("Ð¡ÐšÐÐ§Ð˜Ð’ÐÐÐ˜Ð• Ð˜Ð—ÐžÐ‘Ð ÐÐ–Ð•ÐÐ˜Ð™ ÐŸÐ ÐžÐ”Ð£ÐšÐ¢ÐžÐ’")
    print("=" * 80)
    print()
    
    images_dir = Path("public/images/service")
    images_dir.mkdir(parents=True, exist_ok=True)
    
    services_file = Path("public/fakedata/services.json")
    if not services_file.exists():
        print(f"Ð¤Ð°Ð¹Ð» {services_file} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½!")
        return
    
    with open(services_file, 'r', encoding='utf-8') as f:
        services = json.load(f)
    
    downloaded = {}
    
    for service in services:
        service_id = service.get('id')
        service_title = service.get('title', '')
        
        print(f"ðŸ“¦ Ð¢Ð¾Ð²Ð°Ñ€ {service_id}: {service_title}")
        
        # ÐŸÑ€Ð¾Ð±ÑƒÐµÐ¼ Ð¿Ñ€ÑÐ¼ÑƒÑŽ ÑÑÑ‹Ð»ÐºÑƒ
        if service_id in PRODUCT_URLS:
            url = PRODUCT_URLS[service_id]
            print(f"   ðŸ”— {url}")
            images = extract_images_from_page(url)
            if images:
                img_url = images[0]
                img_filename = f"service-{service_id}.webp"
                img_path = images_dir / img_filename
                
                if download_image(img_url, img_path):
                    print(f"   âœ“ Ð¡ÐºÐ°Ñ‡Ð°Ð½Ð¾: {img_filename}")
                    downloaded[service_id] = f"/images/service/{img_filename}"
                else:
                    print(f"   âœ— ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐºÐ°Ñ‡Ð¸Ð²Ð°Ð½Ð¸Ñ")
            else:
                print(f"   âš  Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹")
        else:
            print(f"   âš  ÐÐµÑ‚ Ð¿Ñ€ÑÐ¼Ð¾Ð¹ ÑÑÑ‹Ð»ÐºÐ¸ - Ð½ÑƒÐ¶Ð½Ð¾ ÑÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Ð²Ñ€ÑƒÑ‡Ð½ÑƒÑŽ")
            print(f"   ðŸ’¡ Ð¡Ð¼. Ð¸Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸ÑŽ Ð² IMAGE_DOWNLOAD_INSTRUCTIONS.md")
        
        print()
    
    print("=" * 80)
    print(f"Ð¡ÐºÐ°Ñ‡Ð°Ð½Ð¾: {len(downloaded)} Ð¸Ð· {len(services)}")
    if downloaded:
        print("\nÐ¡ÐºÐ°Ñ‡Ð°Ð½Ð½Ñ‹Ðµ Ñ„Ð°Ð¹Ð»Ñ‹:")
        for sid, path in downloaded.items():
            print(f"  service-{sid}.webp -> {path}")
    print("=" * 80)

if __name__ == "__main__":
    main()

